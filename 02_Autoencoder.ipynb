{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d02f6b-2dd9-4df9-bfdf-a0f25d5c0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Seung-hwanSong/Anomaly.git #코랩 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6772379",
   "metadata": {},
   "source": [
    "# [시계열 이상치 탐지 Part 2]\n",
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c703c2",
   "metadata": {},
   "source": [
    "##### jupyter notebook 단축키\n",
    "\n",
    "- ctrl+enter: 셀 실행   \n",
    "- shift+enter: 셀 실행 및 다음 셀 이동   \n",
    "- alt+enter: 셀 실행, 다음 셀 이동, 새로운 셀 생성\n",
    "- a: 상단에 새로운 셀 만들기\n",
    "- b: 하단에 새로운 셀 만들기\n",
    "- dd: 셀 삭제(x: 셀 삭제)\n",
    "- 함수 ( ) 안에서 shift+tab: arguments description. shift+tab+tab은 길게 볼 수 있도록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731dc12",
   "metadata": {},
   "source": [
    "## 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 데이터 전처리 패키지 '''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "''' 기계학습 모델 구축 및 평가 패키지 '''\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "''' 데이터 시각화 패키지 '''\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b2bdfb",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오기: NASA Bearing Dataset\n",
    "\n",
    "- 데이터 description <br>\n",
    "    - NASA Bearing Dataset은 NSF I/UCR Center의 Intelligent Maintenance System의 4개의 bearing에서 고장이 발생할 때까지 10분 단위로 수집된 센서 데이터이다. 본 데이터셋은 특정 구간에서 기록된 1-second vibration signal snapshots을 나타내는 여러 개의 파일로 구성되어 있다. 각 파일은 20 kHz 단위로 샘플링 된 20,480개의 data point를 포함하고 있으며, 각 파일의 이름은 데이터가 수집된 시간을 의미한다. 해당 데이터셋은 크게 3개의 데이터를 포함하고 있으며, 본 실습에서 사용하는 데이터는 outer race failure가 발생할 때까지 수집된 센서 데이터이다. <br><br>\n",
    "- 변수\n",
    "    - 센서 데이터: Bearing1, Bearing2, Bearing3, Bearing4 <br><br>\n",
    "- 출처: https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c0e6bb",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/dfFzn3H.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7eab3",
   "metadata": {},
   "source": [
    "### Step1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv('/content/Anomaly/data/nasa_bearing_dataset.csv', index_col=0)\n",
    "# data = pd.read_csv('./data/nasa_bearing_dataset.csv', index_col=0)\n",
    "\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 크기\n",
    "print(\"데이터 크기 : \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8512058",
   "metadata": {},
   "source": [
    "### Step2. 데이터 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c994ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[data['data_type'] == 'train'].iloc[:, :4]\n",
    "\n",
    "X_test = data[data['data_type'] == 'test'].iloc[:, :4]\n",
    "y_test = data[data['data_type'] == 'test'].iloc[:, -2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6760f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.6, random_state=2024)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Validation data shape:\", X_valid.shape)\n",
    "print(\"Test data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c3a08",
   "metadata": {},
   "source": [
    "## 3. Autoencoder\n",
    "### (Auto-Associative Neural Network)\n",
    "\n",
    ">입력과 출력이 동일한 인공신경망 구조 <br>\n",
    ">정상 데이터에 대한 학습이 충분히 되어 있을 경우 정상 데이터는 자기 자신을 잘 복원할 수 있지만, 이상치 제이터는 학습 기회가 적어 상대적으로 잘 복원하지 못할 것을 가정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc8419",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/DTgug9o.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f63750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencdoer 사용을 위한 torch 모듈 불러오기\n",
    "\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f71307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter 설정\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "\n",
    "random_seed = 2024\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Detect if we have a GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b280270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab33bde",
   "metadata": {},
   "source": [
    "### Step 0. 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터를 기반으로 train/validation/test 데이터에 대하여 min-max scaling 적용 \n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c754d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_X_train = scaler.transform(X_train)\n",
    "ae_X_valid = scaler.transform(X_valid)\n",
    "ae_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test dataloader 생성\n",
    "ae_train_dataset = torch.utils.data.TensorDataset(torch.Tensor(ae_X_train))\n",
    "ae_train_loader = torch.utils.data.DataLoader(ae_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "ae_test_dataset = torch.utils.data.TensorDataset(torch.Tensor(ae_X_test))\n",
    "ae_test_loader = torch.utils.data.DataLoader(ae_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50008604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataloader의 경우 train/test 단계에서 사용될 loader를 따로 생성함\n",
    "# train 단계: 정상으로만 구성, test 단계: 정상과 비정상으로 구성\n",
    "ae_X_valid_train = ae_X_valid[y_valid == 0]\n",
    "ae_valid_train_dataset = torch.utils.data.TensorDataset(torch.Tensor(ae_X_valid_train))\n",
    "ae_valid_train_loader = torch.utils.data.DataLoader(ae_valid_train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "ae_valid_test_dataset = torch.utils.data.TensorDataset(torch.Tensor(ae_X_valid))\n",
    "ae_valid_test_loader = torch.utils.data.DataLoader(ae_valid_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87b153",
   "metadata": {},
   "source": [
    "### Step 2. 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36852621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "          nn.Linear(input_size, hidden_size),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "          nn.Linear(hidden_size, input_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc77f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model = AutoEncoder(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36abd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665b16b",
   "metadata": {},
   "source": [
    "### Step 3. Train 데이터로 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e0dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 학습\n",
    "def train_model(dataloaders, model, criterion, num_epochs, learning_rate, device):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_valid_loss = 10000000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch == 0 or (epoch + 1) % 50 == 0:\n",
    "            print()\n",
    "            print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "\n",
    "        # 각 epoch마다 순서대로 training과 validation을 진행\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 모델을 training mode로 설정\n",
    "            else:\n",
    "                model.eval()   # 모델을 validation mode로 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_total = 0\n",
    "\n",
    "            # training과 validation 단계에 맞는 dataloader에 대하여 학습/검증 진행\n",
    "            for i, inputs in enumerate(dataloaders[phase]):\n",
    "                inputs = inputs[0].to(device)\n",
    "\n",
    "                # parameter gradients를 0으로 설정\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # training 단계에서만 gradient 업데이트 수행\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # input을 model에 넣어 output을 도출한 후, loss를 계산함\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, inputs)\n",
    "\n",
    "                    # backward (optimize): training 단계에서만 수행\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # batch별 loss를 축적함\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_total += inputs.size(0)\n",
    "\n",
    "            # epoch의 loss 및 accuracy 도출\n",
    "            epoch_loss = running_loss / running_total\n",
    "\n",
    "            if epoch == 0 or (epoch + 1) % 50 == 0:\n",
    "                print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "\n",
    "            # validation 단계에서 validation loss가 감소할 때마다 best model 가중치를 업데이트함\n",
    "            if phase == 'val' and epoch_loss < best_valid_loss:\n",
    "                best_valid_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # validation loss가 가장 낮았을 때의 best model 가중치를 불러와 best model을 구축함\n",
    "    print('Best validation loss: {:4f}'.format(best_valid_loss))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_dataloaders = {'train': ae_train_loader, 'val': ae_valid_train_loader}\n",
    "ae_train_criterion = nn.MSELoss()\n",
    "ae_model = train_model(ae_dataloaders, ae_model, ae_train_criterion, num_epochs, learning_rate, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef67462",
   "metadata": {},
   "source": [
    "### Step 4. 적합된 모델을 기반으로 train/test 데이터의 anomaly score 도출 (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 검증\n",
    "def test_model(data_loader, model, criterion, device):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = []\n",
    "        for i, inputs in enumerate(data_loader):\n",
    "            inputs = inputs[0].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss = loss.reshape(loss.shape[0], -1).mean(axis=1)\n",
    "\n",
    "            test_loss += list(loss.data.cpu().numpy())\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validation/test 데이터에 대한 최종 결과 도출\n",
    "ae_test_criterion = nn.L1Loss(reduction='none')\n",
    "ae_train_loader = torch.utils.data.DataLoader(ae_train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "ae_train = test_model(ae_train_loader, ae_model, ae_test_criterion, device)\n",
    "ae_valid = test_model(ae_valid_test_loader, ae_model, ae_test_criterion, device)\n",
    "ae_test = test_model(ae_test_loader, ae_model, ae_test_criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724dca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validation/test 데이터의 anomaly score 분포 시각화\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize = (12, 8))\n",
    "\n",
    "sns.distplot(ae_train, bins=100, kde=True, color='blue', ax=ax1)\n",
    "sns.distplot(ae_valid, bins=100, kde=True, color='green', ax=ax2)\n",
    "sns.distplot(ae_test, bins=100, kde=True, color='red', ax=ax3)\n",
    "ax1.set_title(\"Train Data\")\n",
    "ax2.set_title(\"Validation Data\")\n",
    "ax3.set_title(\"Test Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67277d56",
   "metadata": {},
   "source": [
    "### Step 5. Threshold 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70521604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 탐색\n",
    "# score의 min ~ max 범위를 num_step개로 균등 분할한 threshold에 대하여 best threshold 탐색 \n",
    "def search_best_threshold(score, y_true, num_step):\n",
    "    best_f1 = 0\n",
    "    best_threshold = None\n",
    "    for threshold in np.linspace(min(score), max(score), num_step):\n",
    "        y_pred = threshold < score\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print('Best threshold: ', round(best_threshold, 4))\n",
    "    print('Best F1 Score:', round(best_f1, 4))\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best threshold 도출\n",
    "ae_best_threshold = search_best_threshold(ae_valid, y_valid, num_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5fb2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 도출\n",
    "ae_scores = pd.DataFrame(columns=['score', 'anomaly'])\n",
    "for date, score in zip([X_train.index, X_valid.index, X_test.index], [ae_train, ae_valid, ae_test]):\n",
    "    ae_score = pd.DataFrame(index=date)\n",
    "    ae_score['score'] = score\n",
    "    ae_score['anomaly'] = ae_best_threshold < score\n",
    "    ae_scores = ae_scores.append(ae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97358132",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_scores = ae_scores.sort_index()\n",
    "ae_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11770fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anomaly score plot 도출\n",
    "def draw_plot(scores, threshold):\n",
    "    normal_scores = scores[scores['anomaly'] == False]\n",
    "    abnormal_scores = scores[scores['anomaly'] == True]\n",
    "\n",
    "    plt.figure(figsize = (12,5))\n",
    "    plt.scatter(normal_scores.index, normal_scores['score'], label='Normal', c='blue', s=3)\n",
    "    plt.scatter(abnormal_scores.index, abnormal_scores['score'], label='Abnormal', c='red', s=3)\n",
    "    \n",
    "    plt.axhline(threshold, c='green', alpha=0.7)\n",
    "    plt.axvline(data.index[int(len(data) * 0.5)], c='orange', ls='--')\n",
    "    plt.axvline(data.index[int(len(data) * 0.7)], c='orange', ls='--')\n",
    "    \n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Anomaly Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd303a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터의 anomaly score 확인\n",
    "draw_plot(ae_scores, ae_best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fced5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRR, FAR, F1 score, AUROC 도출\n",
    "def calculate_metric(y_true, y_pred):\n",
    "    # FRR, FAR\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[True, False])\n",
    "    tp, fn, fp, tn = cm.ravel()\n",
    "    frr = fp / (fp + tn)\n",
    "    far = fn / (fn + tp) \n",
    "    \n",
    "    # F1 Score\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    # AUROC, IE\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    auroc = auc(fpr, tpr)\n",
    "        \n",
    "    return frr, far, f1, auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 지표 결과 확인\n",
    "frr, far, f1, auroc = calculate_metric(y_test, ae_best_threshold < ae_test)\n",
    "\n",
    "print(\"**  FRR: {}  |  FAR: {}  |  F1 Score: {}  |  AUROC: {}\"\n",
    "      .format(round(frr, 4), round(far, 4), round(f1, 4), round(auroc, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea4ab10",
   "metadata": {},
   "source": [
    "---------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttest3.8",
   "language": "python",
   "name": "ttest3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
